{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOXSRfzG2qXvF+D0NtAhl1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramon-Goveia/DataScience/blob/master/AlgebraLinear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Álgebra Linear para Ciência de Dados\n",
        "\n",
        "A álgebra linear é a base para entender muitos algoritmos de machine learning. Alguns tópicos importantes:"
      ],
      "metadata": {
        "id": "vXAx-w5wTsuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vetores e Matrizes\n",
        "\n",
        "*   Operações com vetores e matrizes: adição, multiplicação, transposição etc.\n",
        "*   Autovalores e autovetores\n",
        "*   Decomposição matricial (LU, QR, SVD)"
      ],
      "metadata": {
        "id": "Gs_8ck5cT4jR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código inclui operações com vetores e matrizes, transposição de matriz, cálculo de autovalores e autovetores, e decomposições matriciais (LU, QR, SVD)."
      ],
      "metadata": {
        "id": "b4eBIZ_LWBFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código utiliza scipy.linalg.lu para a decomposição LU, scipy.linalg.qr para a decomposição QR, e scipy.linalg.svd para a decomposição SVD."
      ],
      "metadata": {
        "id": "EhZVi9-5WECB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFBnRfkPTgCE",
        "outputId": "32f6f146-dd53-47b6-f36f-664a044bc120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Operações com Vetores:\n",
            "Adição de vetores: [5 7 9]\n",
            "Produto escalar de vetores: 32\n",
            "Produto vetorial de vetores: [-3  6 -3]\n",
            "\n",
            "Operações com Matrizes:\n",
            "Adição de matrizes:\n",
            "[[10 10 10]\n",
            " [10 10 10]\n",
            " [10 10 10]]\n",
            "\n",
            "Multiplicação de matrizes:\n",
            "[[ 30  24  18]\n",
            " [ 84  69  54]\n",
            " [138 114  90]]\n",
            "\n",
            "Transposição de Matriz:\n",
            "[[1 4 7]\n",
            " [2 5 8]\n",
            " [3 6 9]]\n",
            "\n",
            "Autovalores e Autovetores:\n",
            "Autovalores: [ 1.61168440e+01 -1.11684397e+00 -1.30367773e-15]\n",
            "Autovetores:\n",
            "[[-0.23197069 -0.78583024  0.40824829]\n",
            " [-0.52532209 -0.08675134 -0.81649658]\n",
            " [-0.8186735   0.61232756  0.40824829]]\n",
            "\n",
            "Decomposição Matricial:\n",
            "LU Decomposition:\n",
            "P * L * U = [[1. 2. 3.]\n",
            " [4. 5. 6.]\n",
            " [7. 8. 9.]]\n",
            "\n",
            "QR Decomposition:\n",
            "Q * R = [[1. 2. 3.]\n",
            " [4. 5. 6.]\n",
            " [7. 8. 9.]]\n",
            "\n",
            "SVD Decomposition:\n",
            "U * S * V = [[1. 2. 3.]\n",
            " [4. 5. 6.]\n",
            " [7. 8. 9.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import lu, qr, svd\n",
        "\n",
        "# Vetores\n",
        "v1 = np.array([1, 2, 3])\n",
        "v2 = np.array([4, 5, 6])\n",
        "\n",
        "# Matrizes\n",
        "A = np.array([[1, 2, 3],\n",
        "              [4, 5, 6],\n",
        "              [7, 8, 9]])\n",
        "\n",
        "B = np.array([[9, 8, 7],\n",
        "              [6, 5, 4],\n",
        "              [3, 2, 1]])\n",
        "\n",
        "# Operações com vetores\n",
        "v_addition = v1 + v2  # Adição de vetores\n",
        "v_dot_product = np.dot(v1, v2)  # Produto escalar de vetores\n",
        "v_cross_product = np.cross(v1, v2)  # Produto vetorial de vetores\n",
        "\n",
        "# Operações com matrizes\n",
        "mat_addition = A + B  # Adição de matrizes\n",
        "mat_multiplication = A.dot(B)  # Multiplicação de matrizes\n",
        "\n",
        "# Transposição de matriz\n",
        "A_transpose = A.T\n",
        "\n",
        "# Autovalores e autovetores\n",
        "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
        "\n",
        "# Decomposição matricial\n",
        "lu_decomposition = lu(A)\n",
        "qr_decomposition = qr(A)\n",
        "svd_decomposition = svd(A)\n",
        "\n",
        "# Impressão dos resultados\n",
        "print(\"Operações com Vetores:\")\n",
        "print(\"Adição de vetores:\", v_addition)\n",
        "print(\"Produto escalar de vetores:\", v_dot_product)\n",
        "print(\"Produto vetorial de vetores:\", v_cross_product)\n",
        "\n",
        "print(\"\\nOperações com Matrizes:\")\n",
        "print(\"Adição de matrizes:\")\n",
        "print(mat_addition)\n",
        "print(\"\\nMultiplicação de matrizes:\")\n",
        "print(mat_multiplication)\n",
        "\n",
        "print(\"\\nTransposição de Matriz:\")\n",
        "print(A_transpose)\n",
        "\n",
        "print(\"\\nAutovalores e Autovetores:\")\n",
        "print(\"Autovalores:\", eigenvalues)\n",
        "print(\"Autovetores:\")\n",
        "print(eigenvectors)\n",
        "\n",
        "print(\"\\nDecomposição Matricial:\")\n",
        "print(\"LU Decomposition:\")\n",
        "print(\"P * L * U =\", lu_decomposition[0] @ lu_decomposition[1] @ lu_decomposition[2])\n",
        "print(\"\\nQR Decomposition:\")\n",
        "print(\"Q * R =\", qr_decomposition[0] @ qr_decomposition[1])\n",
        "print(\"\\nSVD Decomposition:\")\n",
        "print(\"U * S * V =\", svd_decomposition[0] @ np.diag(svd_decomposition[1]) @ svd_decomposition[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "->"
      ],
      "metadata": {
        "id": "yifTqiOLWOPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regressão Linear\n",
        "\n",
        "*   Ajuste de modelo linear (método dos mínimos quadrados)\n",
        "*   Cálculo analítico vs computacional\n",
        "*   Multicolinearidade e redução de dimensionalidade"
      ],
      "metadata": {
        "id": "XXZI0WgZWPtp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código utiliza a biblioteca scikit-learn em Python para realizar uma análise de Regressão Linear. Ele instancia e ajusta um modelo de Regressão Linear aos dados de entrada (X) e saída (y) usando o método dos mínimos quadrados. Os coeficientes (inclinações) e o intercepto do modelo são impressos como resultados. A interpretação desses parâmetros é essencial para entender a relação linear entre as variáveis de entrada e saída. Além disso, o código menciona a possibilidade de lidar com a multicolinearidade e a redução de dimensionalidade usando o método de Componentes Principais (PCA), embora não demonstre a aplicação completa do PCA neste exemplo."
      ],
      "metadata": {
        "id": "ycGlWJ8DYuu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "# Dados de entrada (X) e saída (y)\n",
        "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "y = np.array([2, 5, 8])\n",
        "\n",
        "# Instanciação do modelo de Regressão Linear\n",
        "model = LinearRegression()\n",
        "\n",
        "# Ajuste do modelo usando o método dos mínimos quadrados\n",
        "model.fit(X, y)\n",
        "\n",
        "# Coeficientes (inclinações) do modelo\n",
        "print(\"Coeficientes (inclinações):\")\n",
        "print(model.coef_)\n",
        "\n",
        "# Intercepto do modelo\n",
        "print(\"\\nIntercepto:\")\n",
        "print(model.intercept_)\n",
        "\n",
        "# Comentários sobre Regressão Linear:\n",
        "# - A Regressão Linear modela a relação entre variáveis de entrada (X) e saída (y) assumindo uma relação linear.\n",
        "# - O ajuste do modelo é realizado utilizando o método dos mínimos quadrados para minimizar a soma dos quadrados dos resíduos.\n",
        "\n",
        "# Cálculo analítico vs Computacional:\n",
        "# - O cálculo analítico dos coeficientes e do intercepto pode ser feito de forma direta usando fórmulas matemáticas.\n",
        "# - No entanto, a implementação computacional, como a fornecida pelo scikit-learn, é eficiente e lida automaticamente com casos mais complexos.\n",
        "\n",
        "# Multicolinearidade e Redução de Dimensionalidade:\n",
        "# - A multicolinearidade ocorre quando duas ou mais variáveis de entrada estão altamente correlacionadas.\n",
        "# - Pode ser necessário lidar com a multicolinearidade para evitar instabilidade nos coeficientes estimados.\n",
        "# - A redução de dimensionalidade, como a técnica de Componentes Principais (PCA), pode ser usada para tratar multicolinearidade.\n",
        "\n",
        "# Exemplo de Redução de Dimensionalidade com PCA:\n",
        "pca = PCA(n_components=1)\n",
        "X_reduced = pca.fit_transform(X)\n",
        "\n",
        "# Ajuste do modelo reduzido\n",
        "model.fit(X_reduced, y)\n",
        "\n",
        "# Coeficiente (inclinação) do modelo após redução de dimensionalidade\n",
        "print(\"\\nCoeficiente após redução de dimensionalidade:\")\n",
        "print(model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STzR-pTUWPME",
        "outputId": "b38e7413-405c-4e3a-e50c-d003ccb07aa9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coeficientes (inclinações):\n",
            "[0.75 0.75]\n",
            "\n",
            "Intercepto:\n",
            "-0.25\n",
            "\n",
            "Coeficiente após redução de dimensionalidade:\n",
            "[1.06066017]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "->"
      ],
      "metadata": {
        "id": "8TFWyrE_X6DU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regressão Logística\n",
        "\n",
        "*   Função logística e odds ratio\n",
        "*   Estimativa de parâmetros via máxima verossimilhança\n",
        "*   Matriz de confusão e métricas de classificação"
      ],
      "metadata": {
        "id": "uif5h-GMX75t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código em Python utiliza a biblioteca scikit-learn para implementar um modelo de Regressão Logística. A Regressão Logística é uma técnica estatística frequentemente empregada em problemas de classificação binária. O código inclui a definição de dados de entrada e saída, a instância do modelo de Regressão Logística (LogisticRegression), e o ajuste do modelo aos dados de treinamento. Os coeficientes associados às variáveis de entrada e o intercepto são impressos como resultados do ajuste, oferecendo insights sobre a contribuição de cada variável na previsão da classe de saída."
      ],
      "metadata": {
        "id": "TJmhG0rJZAau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Dados de entrada (X) e saída (y)\n",
        "X = [[0.5], [1.5], [2.5], [3.5]]\n",
        "y = [0, 0, 1, 1]\n",
        "\n",
        "# Instanciação do modelo de Regressão Logística\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# Ajuste do modelo usando os dados de treinamento (X, y)\n",
        "classifier.fit(X, y)\n",
        "\n",
        "# Coeficiente(s) do modelo (associado(s) à(s) variável(is) de entrada)\n",
        "print(\"Coeficiente(s) do modelo:\")\n",
        "print(classifier.coef_)\n",
        "\n",
        "# Intercepto do modelo (termo independente)\n",
        "print(\"\\nIntercepto do modelo:\")\n",
        "print(classifier.intercept_)\n",
        "\n",
        "# Comentários:\n",
        "# - O código utiliza o scikit-learn para criar um modelo de Regressão Logística.\n",
        "# - Os dados de entrada (X) representam as variáveis independentes, e os dados de saída (y) representam as classes (0 ou 1).\n",
        "# - O modelo é treinado (ajustado) utilizando o método da máxima verossimilhança.\n",
        "# - Os resultados do treinamento, ou seja, os coeficientes e o intercepto, são impressos para análise.\n",
        "# - A Regressão Logística é comumente usada para problemas de classificação binária."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3zRZMOCX7J1",
        "outputId": "24acf3dd-b593-42a0-e752-88fc1d19c453"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coeficiente(s) do modelo:\n",
            "[[0.95829214]]\n",
            "\n",
            "Intercepto do modelo:\n",
            "[-1.9165659]\n"
          ]
        }
      ]
    }
  ]
}